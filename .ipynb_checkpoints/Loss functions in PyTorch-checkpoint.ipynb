{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed2122d",
   "metadata": {},
   "source": [
    "List of all the loss functions: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "In the documentation, Input means predicted output and Target means Actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97d8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c136aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.randn(4, 5) #batchsize=4, outputfeature=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a387e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.randn(4, 5) #actual labels. loss=difference between pred and label\n",
    "# from the documentation, we know that, Input and Target must have the same shape for MSE loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a4d24",
   "metadata": {},
   "source": [
    "## MSEloss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7426ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_none = nn.MSELoss(reduction='none')\n",
    "mse_mean = nn.MSELoss(reduction='mean')\n",
    "mse_sum = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a2a63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "printing loss when reduction=none:\n",
      "tensor([[2.1878e-01, 6.8670e-01, 8.0779e-01, 3.3306e-01, 3.4630e-01],\n",
      "        [6.1734e-01, 2.9596e-02, 6.6834e+00, 5.6674e+00, 3.8919e-01],\n",
      "        [8.2051e-02, 1.4095e+00, 5.6830e+00, 3.4098e+00, 9.2345e-02],\n",
      "        [6.0255e-01, 1.5184e+00, 3.1050e-03, 2.7155e-01, 7.1675e-01]])\n",
      "\n",
      "printing loss when reduction=mean:\n",
      "tensor(1.4784)\n",
      "\n",
      "printing loss when reduction=sum:\n",
      "tensor(29.5686)\n"
     ]
    }
   ],
   "source": [
    "loss_none = mse_none(prediction, label)\n",
    "print('\\nprinting loss when reduction=none:')\n",
    "print(loss_none)\n",
    "loss_mean = mse_mean(prediction, label)\n",
    "print('\\nprinting loss when reduction=mean:')\n",
    "print(loss_mean)\n",
    "loss_sum = mse_sum(prediction, label)\n",
    "print('\\nprinting loss when reduction=sum:')\n",
    "print(loss_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3beb9d",
   "metadata": {},
   "source": [
    "- 'mean' calculates the average error, good for overall assessment.\n",
    "- 'sum' adds up all errors, useful for total error evaluation.\n",
    "- 'none' gives you individual squared errors for each data point in the batch, maintaining a separate error value for each prediction. This option is valuable when you need to inspect and possibly address errors on a per-data-point basis, making it suitable for more detailed analysis and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb56cc9",
   "metadata": {},
   "source": [
    "### Now, we are going to write the MSELoss function from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca9a31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, let's implement this loss function from scratch.\n",
    "((prediction-label)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3c643",
   "metadata": {},
   "source": [
    "## Binary cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd390c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use the same prediction dataset\n",
    "#but will take a different dataset for actual values because in BCEloss our labels should be either 0 or 1.\n",
    "label = torch.zeros(4, 5).random_(0,2)  #since target and input have same shape\n",
    "#random_(0,2) is used to put integer values between 0 and 2 (exclusive 2) in label tensor in scatterd way\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385954ec",
   "metadata": {},
   "source": [
    "In PyTorch, an \"inplace operator\" or \"inplace operation\" refers to an operation that modifies a tensor directly, without creating a new tensor as the result of the operation. Inplace operations are typically denoted by an underscore (_) at the end of the method or function name, such as add_(), mul_(), sub_(), random_() etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ce746",
   "metadata": {},
   "source": [
    "Now, define a sigmoid function to pass our prediction tensor through it. Because the BCE loss requires that our input prediction is between range 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ac8ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd147916",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc706eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7365)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce(sigmoid(prediction), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a9166",
   "metadata": {},
   "source": [
    "## BCE with logistic loss\n",
    "This loss combines a Sigmoid layer and the BCELoss in one single class. so we don't need to pass the prediction through a sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8676685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_sig = nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "924a61eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7365)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_sig(prediction, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866e9d9",
   "metadata": {},
   "source": [
    "see same result as BCELoss!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1622b",
   "metadata": {},
   "source": [
    "### Now, we are going to write the BCELoss function from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "593b212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#initally converting tensors in numpy arrays.\n",
    "x = prediction.numpy()\n",
    "y = label.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04eef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since now we are dealing with numpy arrays, so nn.Sigmoid() function won't work\n",
    "#instead we define a function for sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97c73e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7365077211893128\n"
     ]
    }
   ],
   "source": [
    "x = sigmoid(x)\n",
    "loss_values = []\n",
    "for i in range(len(y)):  #len(y) is the number of rows in numpy array\n",
    "    batch_loss=[]\n",
    "    for j in range(len(y[0])):  #len(y[0]) is the number of columns in numpy array\n",
    "        if y[i][j] == 1:\n",
    "            loss = -np.log(x[i][j])\n",
    "        else:\n",
    "            loss =-np.log(1-x[i][j])\n",
    "        batch_loss.append(loss)\n",
    "    \n",
    "    loss_values.append(batch_loss)\n",
    "\n",
    "print(np.mean(loss_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe711522",
   "metadata": {},
   "source": [
    "Alternative but easier way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50b20059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross Entropy Loss: tensor(0.7365)\n"
     ]
    }
   ],
   "source": [
    "y_pred = sigmoid(prediction)\n",
    "y_true = label\n",
    "\n",
    "\n",
    "total_loss = 0.0\n",
    "\n",
    "for i in range(len(y_true)):\n",
    " \n",
    "    \n",
    "    # Calculate binary cross-entropy loss for each example\n",
    "    loss = -(y_true[i] * torch.log(y_pred[i]) + (1 - y_true[i]) * torch.log(1 - y_pred[i]))\n",
    "    \n",
    "    # Add the loss to the total\n",
    "    total_loss += loss\n",
    "\n",
    "# Take the mean of the losses across all examples\n",
    "bce_loss = total_loss / len(y_true)\n",
    "\n",
    "print(\"Binary Cross Entropy Loss:\", bce_loss.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3606a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a21cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d5497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf7c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c3d7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
