{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed2122d",
   "metadata": {},
   "source": [
    "List of all the loss functions: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "In the documentation, Input means predicted output and Target means Actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c136aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.randn(4, 5) #batchsize=4, outputfeature=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.randn(4, 5) #actual labels. loss=difference between pred and label\n",
    "# from the documentation, we know that, Input and Target must have the same shape for MSE loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a4d24",
   "metadata": {},
   "source": [
    "## MSEloss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7426ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_none = nn.MSELoss(reduction='none')\n",
    "mse_mean = nn.MSELoss(reduction='mean')\n",
    "mse_sum = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_none = mse_none(prediction, label)\n",
    "print('\\nprinting loss when reduction=none:')\n",
    "print(loss_none)\n",
    "loss_mean = mse_mean(prediction, label)\n",
    "print('\\nprinting loss when reduction=mean:')\n",
    "print(loss_mean)\n",
    "loss_sum = mse_sum(prediction, label)\n",
    "print('\\nprinting loss when reduction=sum:')\n",
    "print(loss_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3beb9d",
   "metadata": {},
   "source": [
    "- 'mean' calculates the average error, good for overall assessment.\n",
    "- 'sum' adds up all errors, useful for total error evaluation.\n",
    "- 'none' gives you individual squared errors for each data point in the batch, maintaining a separate error value for each prediction. This option is valuable when you need to inspect and possibly address errors on a per-data-point basis, making it suitable for more detailed analysis and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb56cc9",
   "metadata": {},
   "source": [
    "### Now, we are going to write the MSELoss function from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's implement this loss function from scratch.\n",
    "((prediction-label)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3c643",
   "metadata": {},
   "source": [
    "## Binary cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd390c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use the same prediction dataset\n",
    "#but will take a different dataset for actual values because in BCEloss our labels should be either 0 or 1.\n",
    "label = torch.zeros(4, 5).random_(0,2)  #since target and input have same shape\n",
    "#random_(0,2) is used to put integer values between 0 and 2 (exclusive 2) in label tensor in scatterd way\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385954ec",
   "metadata": {},
   "source": [
    "In PyTorch, an \"inplace operator\" or \"inplace operation\" refers to an operation that modifies a tensor directly, without creating a new tensor as the result of the operation. Inplace operations are typically denoted by an underscore (_) at the end of the method or function name, such as add_(), mul_(), sub_(), random_() etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ce746",
   "metadata": {},
   "source": [
    "Now, define a sigmoid function to pass our prediction tensor through it. Because the BCE loss requires that our input prediction is between range 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd147916",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc706eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce(sigmoid(prediction), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a9166",
   "metadata": {},
   "source": [
    "## BCE with logistic loss\n",
    "This loss combines a Sigmoid layer and the BCELoss in one single class. so we don't need to pass the prediction through a sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_sig = nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_sig(prediction, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866e9d9",
   "metadata": {},
   "source": [
    "see same result as BCELoss!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1622b",
   "metadata": {},
   "source": [
    "### Now, we are going to write the BCELoss function from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#initally converting tensors in numpy arrays.\n",
    "x = prediction.numpy()\n",
    "y = label.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since now we are dealing with numpy arrays, so nn.Sigmoid() function won't work\n",
    "#instead we define a function for sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c73e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sigmoid(x)\n",
    "loss_values = []\n",
    "for i in range(len(y)):  #len(y) is the number of rows in numpy array\n",
    "    batch_loss=[]\n",
    "    for j in range(len(y[0])):  #len(y[0]) is the number of columns in numpy array\n",
    "        if y[i][j] == 1:\n",
    "            loss = -np.log(x[i][j])\n",
    "        else:\n",
    "            loss =-np.log(1-x[i][j])\n",
    "        batch_loss.append(loss)\n",
    "    \n",
    "    loss_values.append(batch_loss)\n",
    "\n",
    "print(np.mean(loss_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe711522",
   "metadata": {},
   "source": [
    "Alternative but easier way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b20059",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sigmoid(prediction)\n",
    "y_true = label\n",
    "\n",
    "\n",
    "total_loss = 0.0\n",
    "\n",
    "for i in range(len(y_true)):\n",
    " \n",
    "    \n",
    "    # Calculate binary cross-entropy loss for each example\n",
    "    loss = -(y_true[i] * torch.log(y_pred[i]) + (1 - y_true[i]) * torch.log(1 - y_pred[i]))\n",
    "    \n",
    "    # Add the loss to the total\n",
    "    total_loss += loss\n",
    "\n",
    "# Take the mean of the losses across all examples\n",
    "bce_loss = total_loss / len(y_true)\n",
    "\n",
    "print(\"Binary Cross Entropy Loss:\", bce_loss.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3606a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
